\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{graphicx}
\usepackage{algpseudocode}
\renewcommand{\theequation}{\arabic{equation}}
\newcounter{neq}
\providecommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\QED}{\hfill \textit{\textbf{Q.E.D.}}}
\author{Agustin Curto, agucurto95@gmail.com}
\title{Resumen de teoremas para el final \\ de Matemática Discreta  II}
\date{2016}

\begin{document}
\maketitle
\tableofcontents


\chapter{Parte A}

	\section{La complejidad de EDMONS-KARP}
	
		\textbf{\underline{Teorema:}} La complejidad de $\langle E-K \rangle$ con $n = \abs{V}$ y $m = \abs{E}$ es $\mathcal{O}(nm^{2})$.
	
		\textbf{\underline{Prueba:}} Sean: $f_{0}, f_{1}, f_{2}, \; \dotsc$ \;  la sucesión de flujos creados por $\langle E-K \rangle$. Es decir, el paso \textit{k} crea $f_{k}$.
		
		\vspace{5mm}
		Para cada \textit{k} definimos funciones:
		
		\begin{itemize}
			\item $d_{k}(x) =$ \textquotedblleft distancia\textquotedblright $\;$ entre \textit{s} y x en el paso \textit{k} en caso de existir, si no $\infty$.
			\item $b_{k}(x) =$ \textquotedblleft distancia\textquotedblright $\;$ entre x y \textit{t} en el paso \textit{k} en caso de existir, si no $\infty$.
		\end{itemize}
	
		\textquotedblleft Distancia\textquotedblright: longitud del menor camino aumentante entre dos vértices.
		
		\vspace{5mm}
		Observaciónes:
			\begin{enumerate}
				\item
					\begin{itemize}
						\item $d_{k}(s) = 0$
						\item $b_{k}(t) = 0$
					\end{itemize}
				\item Sabemos que las distancias de $\langle E-K \rangle$ no disminuyen en pasos sucesivos, como esto será útil para esta demostración llamaremos $\circledast$ a la demostración de:
			\begin{center}
				$d_{k}(x) \leq d_{k+1}(x)$ \\
				$b_{k}(x) \leq b_{k+1}(x)$
			\end{center}
			\end{enumerate}

		Llamemos \textit{\underline{crítico}} a un lado disponible en el paso \textit{k} pero no disponible en el paso \textit{k+1}. Es decir, si \textit{xy} es un lado $\Rightarrow$ \textit{xy} se satura ó \textit{yx} se vacía en el paso \textit{k}.
		
		Supongamos que al construir $f_{k}$ el lado \textit{xy} se vuelve crítico, el camino: \textit{s} $\dotsc$ x,y $\dotsc$ \textit{t} se usa para construir $f_{k}$.

		\begin{eqnarray}
			 d_{k}(\textit{t}) & = & d_{k}(x)+ b_{k}(x) \\
			\nonumber & = & d_{k}(x)+b_{k}(y)+1
		\end{eqnarray}
		
		 Para que \textit{xy} pueda ser \textit{crítico} nuevamente debe ser usado en la otra dirección (\textit{i.e yx}). Sea \textit{j} el paso posterior a \textit{k} en el cual se usa el lado en la otra dirección, el camino \textit{s} $\dotsb$ y,x $\dotsb$ \textit{t} se usa para construir $f_{j}$.
		
		\begin{eqnarray}
			d_{j}(\textit{t}) & = & d_{j}(x)+ b_{j}(x) \\
			\nonumber & = & d_{j}(y)+1+b_{j}(x)
		\end{eqnarray}
		
		Entonces:
		
		\begin{equation*}
			\textup{De (1) y (2)} \Rightarrow
  			\left \lbrace
  			\begin{array}{l}
    		 d_{j}(x) = d_{j}(y)+1 \; \; \star \\
     		 d_{k}(y) = d_{k}(x)+1 \; \; \dag\\
  			\end{array}
  			\right.
		\end{equation*}
		
		Luego:

		\begin{eqnarray}
			\nonumber d_{j}(\textit{t}) & = & d_{j}(x)+ b_{j}(x) \\
			\nonumber & = & d_{j}(y)+1+b_{j}(x) \qquad\qquad\qquad\text{Por } \dag\\
			\nonumber & \geq & d_{k}(y)+1+b_{k}(x) \qquad\qquad\qquad\text{Por} \circledast \\
			\nonumber & = & d_{k}(x)+1+1+b_{k}(x) \;\qquad\qquad\text{Por} \star \\
			\nonumber & = & d_{k}(\textit{t})+2 \\
			\nonumber \Rightarrow d_{j}(\textit{t}) & \geq & d_{k}(\textit{t})+2
		\end{eqnarray}
		
		\vspace{5mm}
		Por lo tanto cuando un lado se vuelve crítico recien puede volver a saturarse cuando la distancia de \textit{s} a \textit{t} haya aumentado en por lo menos 2. Puede existir $\mathcal{O}(n/t)$ tales aumentos, es decir:
		
		\begin{center}
			\# Veces que un lado puede volverse crítico $= \mathcal{O}(n)$. 
		\end{center}				
		
		\begin{eqnarray}
			 \nonumber \; \therefore Complejidad(\langle E-K \rangle) &=& (\# pasos) * Compl(1 \; \textit{paso}) \\
			 \nonumber &=& (\# \textup{veces que un lado se vuelve crítico}) * (\# lados) * Compl(BFS) \\
			\nonumber  &=& \mathcal{O}(n) * \mathcal{O}(m)* \mathcal{O}(m) \\
			\nonumber &=& \mathcal{O}(nm^{2})
		\end{eqnarray}
			
		
	\section{Las distancias de Edmonds-Karp no disminuyen en pasos sucesivos}
		\underline{Teorema:} Sean: $f_{0}, f_{1}, f_{2}, \; \dotsc$ \;  la sucesión de flujos creados por $\langle E-K \rangle$. Es decir, el paso \textit{k} crea $f_{k}$.
		
		\vspace{5mm}
		Para cada \textit{k} definimos funciones:
		
		\begin{itemize}
			\item $d_{k}(x) =$ \textquotedblleft distancia\textquotedblright $\;$ entre \textit{s} y x en el paso \textit{k} en caso de existir, si no $\infty$.
			\item $b_{k}(x) =$ \textquotedblleft distancia\textquotedblright $\;$ entre x y \textit{t} en el paso \textit{k} en caso de existir, si no $\infty$.
		\end{itemize}
	
		\textquotedblleft Distancia\textquotedblright: longitud del menor camino aumentante entre dos vértices.
		
		\vspace{5mm}
		Queremos probar que:
		\begin{enumerate}
			\item $d_{k}(x) \leq d_{k+1}(x)$
			\item $b_{k}(x) \leq b_{k+1}(x)$
		\end{enumerate}
		
		\underline{Prueba:} Lo probaremos por inducción y solo para $d_{k}$ ya que para $b_{k}$ la prueba es análoga.
		
		\begin{center}
			HI: $H(i) = \lbrace\forall_{z}: d_{k+1}(z) \leq \textit{i}, \, vale \; d_{k}(z) \leq d_{k+1}(z)  \rbrace$
		\end{center}
		
		\begin{enumerate}
			\item Caso Base: \begin{tabular}{|c|} \hline i = 0 \\ \hline \end{tabular} \qquad	$H(0) = \lbrace\forall_{z}: d_{k+1}(z) \leq 0, \, d_{k}(z) \leq d_{k+1}(z)  \rbrace$
			
			Pero $d_{k+1}(z) \leq 0 \Rightarrow z = \textit{s}$
			
			\begin{eqnarray}
				\nonumber d_{k}(z) & = & d_{k}(\textit{s}) \\
				\nonumber & = & 0 \\
				\nonumber & \leq & d_{k+1}(\textit{s}) \\
				\nonumber & \leq & d_{k+1}(z) \\
				\nonumber \Rightarrow d_{k}(z) & \leq & d_{k+1}(z)
			\end{eqnarray}
			
			\item Caso Inductivo: Supongamos ahora que vale H(\textit{i}), veamos que vale H(\textit{)i+1}.
			
			Sea \textit{z} con $d_{k+1}(z) \leq \textit{i+1}$, si $d_{k+1}(z) \leq \textit{i}$ vale H(\textit{i}) para \textit{z}. 
			
			\begin{center} $\therefore \; d_{k+1}(z) \leq d_{k+1}(z) $ \end{center}
			
			Supongamos que \begin{tabular}{|c|} \hline $d_{k+1}(z) = i+1$ \\ \hline \end{tabular}
			
			Entonces existe un camino aumentante, relativo a $f_{k}$, de la forma: $s = z_{0}, \; z_{1}, \; \dotsc \; z_{i}, \; z_{i+1} = z$.
			
			Sea \begin{tabular}{|c|} \hline $x = z_{i}$ \\ \hline \end{tabular}
			
			\begin{itemize}
				\item \underline{Caso 1:} Existe algun camino aumentante, relativo a $f_{k-1}$ de la forma $s, \; \dotsc \; x, \; z$.
				$\Rightarrow \begin{tabular}{|c|} \hline $d_{k}(x) \leq d_{k}(x) + 1$ \\ \hline \end{tabular}$
				
				\vspace{2mm}
				Pues al haber un camino $\underbrace{s, \; \dotsc \; x,}_{d_{k}(x)} \; z$, llamemosle A, de longitud $d_{k}(x) + 1$ entre \textit{s} y \textit{z}, sabemos que el minimo de todos los caminos de \textit{s} a \textit{z} seran $\leq$ A.
				
				\item Caso 2: No existe un camino aumentante, relativo a $f_{k-1}$, pero si existe un camino aumentante relativo a $f_{k}$. Por lo tanto el lado \textit{xz} no esta \textquotedblleft disponible\textquotedblright \; en el paso \textit{k}, ya que \textit{xz} está saturado \textit{zx} está vacío relativo a $f_{k-1}$. Para construir $f_{k}$ usamos un camino de la forma $s, \; \dotsc \; z, \; x$. Es decir:
				
				\begin{enumerate}[1)]
					\item $f_{k-1}(xz) = C(xz)$ pero $f_{k}(xz) < C(xz), \; f_{k}$ devuelve flujo por \textit{xz} ó
					\item $f_{k-1}(zx) = 0$ pero $f_{k}(zx) > 0, \; f_{k}$ manda flujo por \textit{zx}.
				\end{enumerate}
				
				Como $\langle E-K \rangle$ funciona con BFS, ese camino usado pra construir $f_{k}$ debe ser de longitud mínima. Es decir: \; $d_{k}(x) = d_{k}(z) + 1$
				
				\begin{eqnarray}
					\nonumber d_{k}(z) & = & d_{k}(x) - 1 \\
					\nonumber & \leq & d_{k}(x) + 1
				\end{eqnarray}				
			\end{itemize}
			
			\underline{Conclusión:} En cualquiera de los dos casos tenemos:
			\begin{center}
			\begin{tabular}{|c|} \hline $d_{k}(x) \leq d_{k}(x) + 1$ \\ \hline \end{tabular}
			\end{center}
			
			Ahora bien: \qquad $d_{k+1}(x) = d_{k+1}(z_{i}) = i \; \; \Rightarrow \; \;$ vale H(\textit{i}) para x. \\
			$ \; \qquad \qquad \therefore d_{k}(z) \leq d_{k+1}(x)$
			
			\begin{eqnarray}
					\nonumber d_{k+1}(x) & = & d_{k+1}(z_{i}) \\
					\nonumber & = & i \\
					\nonumber & \Rightarrow & \textup{H(\textit{i}) vale para x.} \\
					\nonumber \therefore \; d_{k}(z) & \leq & d_{k+1}(x)
				\end{eqnarray}
			
			Por lo tanto:
			\begin{eqnarray}
					\nonumber d_{k}(z) & \leq & d_{k}(x) + 1 \\
					\nonumber & \leq & d_{k+1}(x) + 1 \\
					\nonumber & = & i+1 \\
					\nonumber & = & d_{k+1}(z) \\
					\nonumber & \Rightarrow & \textup{H(\textit{i+1}) vale.}
				\end{eqnarray}
		\end{enumerate}


	\section{La complejidad de DINIC}

		\underline{Teorema:} La complejidad del algoritmo de Dinic es $\mathcal{O}(n^{2}m)$.
		
		\underline{Prueba:} Como Dinic es un algoritmo que trabaja con networks auxiliares y vimos que la distancia entre \textit{s} y \textit{t} en networks auxiliares consecutivos aumenta y puede ir a lo sumo entre 1 y $n-1$ entonces hay a lo sumo $\mathcal{O}(n)$ networks auxiliares.

		\begin{center}
			Complejidad(Dinic)$ = \mathcal{O}(n) *$ Compl(Hallar un flujo bloqueante en un NA con Dinic)
		\end{center}
		
		Para probar que la complejidad de Dinic es $\mathcal{O}(n^{2}m)$ debemos probar que complejidad del paso bloqueante es $\mathcal{O}(nm)$.
		
		Sea:
		\begin{itemize}
			\item A $=$ Avanzar()
			\item R $=$ Retroceder()
			\item I $=$ Incrementar\_Flujo + Inicialización ($\mathcal{O}(1)$) 
		\end{itemize}

		Una corrida de Dinic luce como:
		\begin{center}
			AA$\; \dotsc \;$AIAAARA$\; \dotsc \;$AIAARAAARR$\; \dotsc \;$IA$\; \dotsc \;$
		\end{center}
		
		Dividamos la corrida en subpalabras del tipo:
		\begin{center}
			\begin{itemize}
				\item[$*$] $\underbrace{AA \; \dotsc \; A}_{Todas A's}I$
				\item[$*$] $\underbrace{AA \; \dotsc \; A}_{Todas A's}R$
			\end{itemize}
		\end{center}
		
		Nota: el número de A's puede ser 0.
		
		Debemos determinar:
		\begin{enumerate}
			\item Cual es la complejidad de cada subpalabra.
			\item Cuantas palabras hay de cada tipo.
		\end{enumerate}
		
		\textbf{Complejidad de cada subpalabra}
		
		Recordemos que:
		\begin{equation*}
			\textup{A:}
  			\left[
  			\begin{array}{l}
    		 P[i+1] = \textup{algún elemento de } \Gamma^{+}(P[i]) \\
     		 i = i+1\\
  			\end{array}
  			\right.
		\end{equation*}
		\begin{center}
			$\Rightarrow$ A es $\mathcal{O}(1)$
		\end{center}
		
		\begin{equation*}
			\textup{R:}
  			\left[
  			\begin{array}{l}
    		 P[i+1] = \textup{borrar } P[i-1]P[i] \textup{ del NA} \\
     		 i = i-1\\
  			\end{array}
  			\right.
		\end{equation*}
		\begin{center}
			$\Rightarrow$ R es $\mathcal{O}(1)$
		\end{center}
		
		\begin{equation*}
			\textup{I:}
  			\left[
  			\begin{array}{l}
    		 P[i+1] = \textup{recorre 2 veces, un camino de longitud } d = d(t)
  			\end{array}
  			\right.
		\end{equation*}
		\begin{center}
			$\Rightarrow$ I es $\mathcal{O}(d)$
		\end{center}
		
		Por lo tanto:
		\begin{eqnarray}
			\nonumber Compl(\underbrace{A \; \dotsc \; A}_{j \; veces}R) & = & \underbrace{\mathcal{O}(1) + \; \dotsc \; \mathcal{O}(1)}_{j \; veces} + \mathcal{O}(1) \\
			\nonumber & = & \mathcal{O}(j) + \mathcal{O}(1) \\
			\nonumber & = & \mathcal{O}(j)
		\end{eqnarray}
		
		Pero como cada A hace $ i = i+1$ y tenemos $ 0 \leq \textit{i} \leq \textit{d} \; \Rightarrow \; \textit{j} \leq \textit{d}.$
		
		\begin{center}
			$\therefore \; Compl(A \; \dotsc \; AR) = \mathcal{O}(\textit{d})$
		\end{center}
		
		Similarmente: 		
		\begin{eqnarray}
			\nonumber Compl(A \; \dotsc \; AI) & = & \underbrace{\mathcal{O}(1) + \; \dotsc \; \mathcal{O}(1)}_{\leq \; d \; veces} + \mathcal{O}(1) \\
			\nonumber & = & \mathcal{O}(d) + \mathcal{O}(1) \\
			\nonumber & = & \mathcal{O}(d)
		\end{eqnarray}
				
		\textbf{Cantidad de subpalabras}
		\begin{itemize}
			\item R tiene la instrucción "\textbf{borrar lado}". Como los lados borrados quedan borrados hay a lo sumo \textit{m} R's, es decir:
			\begin{center}
				$ \therefore \; \# (A \; \dotsc \; AR's) \leq m $
			\end{center}
			
			\item I tiene también línes de la forma:
				\begin{algorithmic}
					\If{$\dotsc$}
    					\State{borrar lado}
    				\EndIf
				\end{algorithmic}
			 	
			 	Lo que está dentro del \textbf{if} se cumple al menos una vez, es decir:
			 	\begin{center}
					$ \therefore \; \# (A \; \dotsc \; AI's) \leq m $
				\end{center}
			
			Este análisis muestra que:
			\begin{center}
					$ \therefore \; \# (A \; \dotsc \; AR's) + \# (A \; \dotsc \; AI's) \leq m $
				\end{center}
			
			Por lo tanto hay $\leq m$ palabras, cada una de complejidad $\mathcal{O}(d)$.

			\begin{eqnarray}
			\nonumber \therefore \;  Compl(Paso \; Bloqueante) & = & \mathcal{O}(m) + \mathcal{O}(md) \\
			\nonumber & = & \mathcal{O}(mn)
		\end{eqnarray}
		
		ya que $d \leq n$.			
		\end{itemize}
		

	\section{La complejidad de WAVE}

		\underline{Teorema:} La complejidad del algoritmo de Wave es $\mathcal{O}(n^{3})$.
		
		\underline{Prueba:} Como Wave es un algoritmo que trabaja con networks auxiliares y vimos que la distancia entre \textit{s} y \textit{t} en networks auxiliares consecutivos aumenta y puede ir a lo sumo entre 1 y $n-1$ entonces hay a lo sumo $\mathcal{O}(n)$ networks auxiliares.

		\begin{center}
			Complejidad(Wave)$ = \mathcal{O}(n) *$ Compl(Hallar un flujo bloqueante en un NA con Wave)
		\end{center}
		
		Para probar que la complejidad de Wave es $\mathcal{O}(n^{3})$ debemos probar que complejidad del paso bloqueante es $\mathcal{O}(n^{2})$. El paso bloqueante de Wave consiste en una serie de:
		
		\begin{itemize}
			\item Olas hacia adelante: Sucesión de \textbf{forwrdbalance} (FB)
			\item Olas hacia atrás: Sucesión de \textbf{backwardbalance} (BB)
		\end{itemize}
		
		Cada FB y BB es una sucesión de \textquotedblleft \textbf{buscar vecinos}\textquotedblright y \textquotedblleft \textbf{procesar}\textquotedblright el lado resultante. Estos "procesamientos" \; son complicados pero $ \mathcal{O}(1)$.
		
		\begin{center}
		$ \therefore \; Compl(Paso \; Bloqueante) = \# "procesamientos"$ de lados
		\end{center}
	
		Los "procesamientos" \; de lados los podemos dividir en dos categorías:
		\begin{enumerate}
			\item Aquellos procesamientos que saturan o vacian el lado. Denotaremos \textquotedblleft T\textquotedblright \; al número de estos procesamientos.
			\item Aquellos procesamientos que no saturan ni vacian el lado. Denotaremos \textquotedblleft Q\textquotedblright \; al número de estos procesamientos.
		\end{enumerate}
	
		Por lo tantos queremos acotar $T + Q$.
		
		\vspace{5mm}
		\textbf{Complejidad de T:}
		\begin{itemize}
			\item ¿Puede un lado \textit{xy} saturado volver a saturarse?
			
			Para poder volver a \underline{saturarse} primero tiene que vaciarse auque sea un poco, es decir, antes de poder volver a saturarlo \textquotedblleft \textit{y}\textquotedblright \; debe devolver flujo a \textquotedblleft \textit{x}\textquotedblright \;, pero para que en Wave \textquotedblleft \textit{y}\textquotedblright \; le devuelva flujo a \textquotedblleft \textit{x}\textquotedblright \;  debe ocurrir que \textquotedblleft \textit{y}\textquotedblright \; este bloqueado (porque BB(y) solo se ejecuta si \textquotedblleft \textit{y}\textquotedblright \; está bloqueado), pero si \textquotedblleft \textit{y}\textquotedblright \; está bloqueado \textquotedblleft \textit{x}\textquotedblright \; no puede mandarle flujo nunca más.
			
			\begin{center}
				$ \therefore \;$ \textit{xy} no puede resaturarse
			\end{center}
			
			\underline{Conclusión 1:} Los lados se saturan solo una vez.
			
			\item ¿Puede un lado \textit{xy} vaciado completamente volver a vaciarse?
			
			Para poder volver a \underline{vaciarse} como está vacío completamente, primero hay que mandar flujo, pero si lo vacié \textquotedblleft \textit{y}\textquotedblright \; está bloqueado por lo que \textquotedblleft \textit{x}\textquotedblright \; no puede mandar flujo.
			
			\begin{center}
				$ \therefore \;$ \textit{xy} no puede volver a vaciarse
			\end{center}
			
			\underline{Conclusión 2:} Los lados se vacían completamente a lo sumo una vez.
			
			Las conclusiones (1) y (2) implican que \begin{tabular}{|c|} \hline $T \leq 2 \; m$ \\ \hline \end{tabular}
		\end{itemize}
	
		\textbf{Complejidad de Q:}
	
			En cada FB a lo sumo un lado no se satura y en cada BB a lo sumo un lado no se vacía completamente.
			
			\vspace{2mm}
			$\therefore \;$ Q $\leq \#$ Total de FB's y BB's 
	
			\begin{itemize}
				\item $\#$ FB's en cada ola hacia adelante es $\leq$ \textit{n} (un FB por vértice)
				\item $\#$ BB's en cada ola hacia atrás es $\leq$ \textit{n}

				$\therefore$ Total de FB's y BB's $\leq 2 \; n \; \#$Total de ciclos de \textquotedblleft ola adelante $-$ ola hacia atrás\textquotedblright
 			\end{itemize}
	
			Ahora bien, en cada ola hacia adelante, pueden o no, bloquearse algunos vértices. Si no se bloquea ningún vértice entonces todos los vértices ($\neq$ \textit{s, t}) quedan balaceados por lo que estamos en la última ola. Luego en toda ola que no sea la última se bloquea al menos un vértice ($\neq$ \textit{s, t}).
			
			\begin{center}
			$\therefore \; \#$Total de ciclos es $\leq (n-2)+1 = n-1$ \\
			$\Rightarrow$ \begin{tabular}{|c|} \hline $Q \; \leq 2 n (n-1) = \mathcal{O}(n^{2})$ \\ \hline \end{tabular}
			\end{center}
	
			\begin{eqnarray}
				\nonumber \therefore \; T + Q & \leq & 2 m + \mathcal{O}(n^{2}) \\
				\nonumber & = & \mathcal{O}(m) + \mathcal{O}(n^{2}) \\
				\nonumber & = & \mathcal{O}(n^{2})
			\end{eqnarray}


	\section{La distancia entre NA sucesivos aumenta}
	
		\underline{Teorema:} Sea A un NA (network auxiliar) y sea $A^{*}$ el siguiente NA. Sean d(x) y $d^{*}(x)$ las distancias de \textit{s} a \textit{t} en A y $A^{*}$ respectivamente, entonces: $d(t) < d^{*}(t)$.
		
		\underline{Prueba:} Como A y $A^{*}$ se construyen con BFS sabemos que $d(t) \leq d^{*}(t)$ pero queremos ver el $<$.
		
		Sea:
		\begin{center}
			$s = x_{0}, \; x_{1}, \; \dotsc \; t = x_{r}$
		\end{center}
	
		un camino dirigido en $A^{*}$.
	
		Ese camino \begin{tabular}{|c|} \hline No existe \\ \hline \end{tabular} en A ya que para pasar de A a $A^{*}$ debemos bloquear todos los caminos dirigidos de A. Por lo tanto si ese camino estuviese en A, Dinic lo habría bloqueado y no estaría en $A^{*}$.
		
		\textbf{¿Cuáles son las razones posibles para que no esté en A?}
		\begin{enumerate}
			\item Puede faltar un vértice, es decir $\exists \; i \; : \; x_{i} \; \nexists \; V(A)$ entonces:
			\begin{eqnarray}
				\nonumber d(t) & \leq & d(x_{i}) \\
				\nonumber & \leq & d^{*}(x_{i}) \\
				\nonumber & = & i < r \\
				\nonumber & = & d^{*}(t) \\
				\nonumber \begin{tabular}{|c|} \hline $\therefore \; d(t) < d^{*}(t)$ \\ \hline \end{tabular}
			\end{eqnarray}
			
			\item Están todos los vértices pero falta una arista, es decir $\exists \; i \; : \; x_{i}x_{i+1} \; \nexists \; E(A)$.
			\begin{enumerate}[a)]
				\item $x_{i}x_{i+1}$ no está porque corresponde a un lado vacío o saturado en NA, es decir $x_{i}x_{i+1}$ no está en el recidual que dá origen a A pero si está en el residual que dá origen a $A^{*}$.
				
				Para que esto pase se tiene que haber usado el lado $x_{i+1}x_{i}$ en A. Luego podemos cocluir, por la prueba de $\langle E-K \rangle$ que:
				\begin{center}
					$\qquad \; d^{*}(t) \geq d(t) + 2 > d(t) $
					
					\vspace{2mm}
					\begin{tabular}{|c|} \hline $\therefore \; d(t) < d^{*}(t)$ \\ \hline \end{tabular}
				\end{center}
				
				\item $x_{i}x_{i+1}$ si está en el residual pero:
				\begin{tabular}{|c|} \hline $d(x_{i+1}) \neq d(x_{i}) +1 $ \\ \hline \end{tabular} (1)
				
				\vspace{5mm}
				Pero como $x_{i}x_{i+1}$ está en el residual entonces:
				\begin{tabular}{|c|} \hline $d(x_{i+1}) \leq d(x_{i}) +1 $ \\ \hline \end{tabular} (2)
				
				\vspace{5mm}
				De (1) y (2) tenemos que: \begin{tabular}{|c|} \hline $d(x_{i+1}) < d(x_{i}) +1 $ \\ \hline \end{tabular} $\circledast$
			
				Entonces:
				\begin{eqnarray}
				\nonumber d(t) & = & d(x_{i+1}) + b(x_{i+1}) \qquad\;\;\;\;\;\textup{Por }\langle E-K \rangle\\
				\nonumber & \leq & d(x_{i+1}) + b^{*}(x_{i+1}) \qquad\;\;\;\;\textup{Por }\langle E-K \rangle\\
				\nonumber & < & d(x_{i}) +1 + b^{*}(x_{i+1}) \qquad\;\textup{Por } \circledast \\
				\nonumber & \leq & d^{*}(x_{i}) + 1 + b^{*}(x_{i+1}) \qquad\textup{Por }\langle E-K \rangle \\
				\nonumber & = & d^{*}(x_{i+1}) + b^{*}(x_{i+1}) \qquad\;\;\;\textup{Por } (\dag) \\
				\nonumber & = & d^{*}(t)
				\end{eqnarray}
				$\qquad\qquad\qquad\;\;\;$
				\begin{tabular}{|c|} \hline $\therefore \; d(t) < d^{*}(t)$ \\ \hline \end{tabular}

				($\dag$): Ya que $s, \; x_{1}, \; \dotsc \; x_{r}$
			\end{enumerate}
		\end{enumerate}
	
	
	






\chapter{Parte B}

	\section{2-COLOR es polinomial}
	
	
	\section{Teorema Max-Flow Min-Cut}
		\underline{Teorema:}
		\begin{enumerate}[a)]
			\item Si \textit{f} es flujo y S es corte $\Rightarrow$ V(\textit{f}) $\leq$ Cap(S).
			\item Si V(\textit{f}) $=$ Cap(S) $\Rightarrow$ \textit{f} es maximal y S es minimal.
			\item Si \textit{f} es maximal $\Rightarrow \exists$ S con V(\textit{f}) $=$ Cap(S).
		\end{enumerate}
		
		\underline{Prueba:} Demostraremos primero que $V(\textit{f}) = f(S, \overline{S}) - f(\overline{S},S)$ donde \textit{f} es un flujo y S un corte. Esto nos ayudará en la demostración del ítem a).
		
		\underline{Observemos que:}
		\begin{itemize}
			\item $f(A \cup B, C) = f(A,C) + f(B,C):$ A y B disjuntos.
			\item $f(A, B \cup C) = f(A,B) + f(A,C):$ B y C disjuntos.
			\item $f(A, B) = \sum_{\begin{subarray}{l} x \in A\\
y \in B\end{subarray}} f(x, y)$.
		\end{itemize}

		Sea x $\in$ S $\Rightarrow$ x $\neq$ \textit{t}.
		\begin{equation*}
			\textup{f(x, V) - f(V, x)} =
  			\left\lbrace
  			\begin{array}{l}
    		 V(f) \; Si \; x= \textit{s} \\
     		 0 \; \; \; \; \; \; \;  Si \; x \neq \textit{s} \; pues \; \textit{t} \notin S \\
  			\end{array}
 			 \right.
		\end{equation*}
		
		Luego:
		\begin{eqnarray}
			\nonumber \sum_{x \in S}(f(x, V) - f(V, x)) & = & 0 + 0 \dotsb + V(f) \\
			\nonumber & = & V(f)
		\end{eqnarray}
		
			\begin{eqnarray}
			\nonumber V(f) & = & \sum_{x \in S}f(x, V) - \sum_{x \in S}f(V, x) \\
			\nonumber & = & f(S, V) - f(V, S) \;\;\qquad\qquad\qquad\qquad\qquad\qquad\text{Por observación} \\
			\nonumber & = & f(S, S \cup \overline{S}) - f(S \cup \overline{S}, S) \;\;\;\;\qquad\qquad\qquad\qquad\text{Ya que } V = S \cup \overline{S} \\
           \nonumber & = & f(S, S) + f(S, \overline{S}) - f(S, S) -  f(\overline{S}, S) \qquad\qquad\text{Por observación} \\
           \nonumber & = & \begin{tabular}{|c|} \hline $f(S, \overline{S} - f(\overline{S}, S))$ \\ \hline \end{tabular} \; \star
		\end{eqnarray}

		\textbf{a) \textit{f} es flujo y S es corte $\Rightarrow$ V(\textit{f}) $\leq$ Cap(S).}
		
			\begin{center}
				$V(f) =_{\star} f(S, \overline{S})\underbrace{-\underbrace{f(\overline{S}, S)}_{\geq 0}}_{\leq 0}$ \\
				\vspace{5mm}
				$\Rightarrow V(f ) \leq f(S, \overline{S}) \leq C(S, \overline{S}) =$ Cap(S)
			\end{center}
			
		\textbf{b) V(\textit{f}) $=$ Cap(S) $\Rightarrow$ \textit{f} es maximal y S es minimal.}

			\vspace{5mm}
			Supongamos que V(\textit{f}) $=$ Cap(S).
			
			Sea \textit{g} un flujo cualquiera y T un corte cualquiera.
			\begin{itemize}
				\item $V(g) \leq_{a)} Cap(S) = V(f) \Rightarrow$ f es maximal 
				\item $Cap(T) \leq_{a)} V(f) = Cap(S) \Rightarrow$ S es minimal
			\end{itemize}
			
		\textbf{c) \textit{f} es maximal $\Rightarrow \exists$ S con V(\textit{f}) $=$ Cap(S).}
		
		\vspace{5mm}
		
		
		
	\section{Complejidad del Hungaro es $\mathcal{O}(n^{4})$}
	
		\underline{Teorema:} La complejidad del algoritmo Húngaro es $\mathcal{O}(n^{4})$.
		
		\underline{Prueba:} 
		
			\begin{enumerate}
				\item La complejidad del matching inicial es $\mathcal{O}(n^{2})$, ya que:
				
					Restar mínimo de cada fila:
					\begin{center}
						$(\mathcal{O}(n^{2}) + \mathcal{O}(n^{2})) * n = \mathcal{O}(n^{2})$
						Idem para las columnas.
					\end{center}
				
				\item Llamemos \textbf{extender} el matching, a incrementar su número de filas en 1, i.e agregar una fila más al matching.
				\begin{center}
					$ \# \; extensiones \; de \; matching = \mathcal{O}(n)$
				\end{center}
				
				Resta ver la complejidad de cada \textbf{extender}.
				
				\item En cada extensión vamos a ir revisando filas y columnas, donde escanear una fila es $\mathcal{O}(n)$ y se realizan \textit{n} escaneos, por lo que sería $\mathcal{O}(n^{2})$ sin considerar que se debe realizar un cambio de matriz.
				
				Hacer un cambio de matriz es $\mathcal{O}(n^{2})$.				
				\begin{itemize}
					\item Buscar $\textit{m} = \min S \; x \; \overline{\Gamma(S)} \rightarrow \mathcal{O}(n^{2})$
					\item Restar \textit{m} de $S \rightarrow \mathcal{O}(n^{2})$
					\item Sumar \textit{m} a $\Gamma(S) \rightarrow \mathcal{O}(n^{2})$
				\end{itemize}
				
				Luego la implementación NAIVE lanzaría nuevamente el algoritmo desde cero. La forma correcta es continuar con el matching que teniamos, ya que el mismo no se pierde.
				\begin{center}
				$
				\begin{bmatrix}
				A & A \\
				B  & C \\
				\end{bmatrix}					
				$
				\end{center}
				
				TO DO
				
				Debemos ver cuantos Cambios de matriz hay antes de extender nuevamente un matching
				
				\underline{\textbf{Lema Interno:}} Luego de un cambio de matriz, se extiende el matching (i.e se termina el \textbf{extender}), o bien se aumenta S.
				
				\underline{\textbf{Prueba:}} 
				
				\begin{center}
				$
				\begin{bmatrix}
				A & A \\
				B  & C \\
				\end{bmatrix}					
				$
				\end{center}				
				
				Al restar $\textit{m} = \min S \; \Gamma(S)$ de las filas de S, habrá un nuevo cero en alguna fila \textit{i} ($\in S$) y columna \textit{j} ($\in \Gamma(S)$) entonces la columna se etiquetará con \textit{i} y se revisará.
				Tenemos dos resultados posible:
				\begin{enumerate}
					\item \textit{j} está libre (i.e no forma parte del matching) $\Rightarrow$ extendemos el matching.
					\item \textit{j} forma parte de matching $\Rightarrow \exists$ fila \textit{k} matcheada con \textit{j}. En este caso, la fila \textit{k} se etiquetará con \textit{j}, por lo que el "nuevo" $\; S \geq S \cup \{\textit{k}\}$.
					
					\vspace{5mm}
					Entonces se termina con una extensión o se produce un nuevo S de cardinalidad, al menos $\lvert S \rvert + 1$.
				\end{enumerate}
				
				\textbf{Fin lema interno}
				
				Luego como $\lvert S \rvert$ solo puede crecer $\mathcal{O}(n)$ veces, tenemos que hay a lo sumo \textit{n} \textbf{cambios de matriz} antes de extender el matching. Entonces:
				
							\begin{center}
								Complejidad(1 Extensión) $= \underbrace{\mathcal{O}(n)}_{\# CM} * \underbrace{\mathcal{O}(n^{2})}_{Compl(CM)} + \underbrace{\mathcal{O}(n^{2})}_{Busqueda \; \textit{n} \; filas \; x \; \textit{n} \; columnas }$ \\
								\vspace{5mm}
								$\therefore$ Complejidad(Húngaro) $= \underbrace{\mathcal{O}(n^{2})}_{Matching inicial} + \underbrace{\mathcal{O}(n)}_{\#extensiones} * \underbrace{\mathcal{O}(n^{3})}_{Compl(extension)}$
							\end{center}				
			\end{enumerate}
	
	\section{Teorema de Hall}
	
		\underline{Teorema:} Sea G = (x $\cup$ y, E) grafo bipartito $\Rightarrow \exists$ matching completo de X a Y $\Leftrightarrow \; \lvert S \rvert = \lvert \Gamma(S) \rvert \forall S \subseteq X$.
		
		\underline{Prueba:}

			$\Rightarrow)$ Si M es matching comple de X a Y entonces oberservemos que M induce una función inyectiva de X a Y.
			
			\begin{center}
				$f(x) = $ único y : xy $\in$ M.
			\end{center}
			
			\begin{enumerate}
				\item Si $S \subseteq X \Rightarrow \lvert S \rvert = \lvert \Gamma(S) \rvert$. \\
				
				Además por definición de f, $f(x) \in \Gamma(x)$.
				\item Si $x \in S \Rightarrow f(x) \in \Gamma(S)
				\Rightarrow f(S) \subseteq \Gamma(S)$.
			\end{enumerate}
			
			De \textcircled{1} y \textcircled{2} $\Rightarrow \lvert S \rvert \leq \lvert \Gamma(S) \rvert$.
			
			\vspace{5mm}
			$\Leftarrow)$ Supongamos que no es cierto, entonces G es bipartito con $\lvert S \rvert \leq \lvert \Gamma \rvert \; \forall \; S \subseteq X$ pero no tiene matching completo de X a Y. Es equivalente a ver que: Si $\nexists$ un matching completo $\Rightarrow \exists \; S \subseteq X : \lvert S \rvert > \lvert \Gamma(S) \rvert$.
			
			\vspace{5 mm}
			Corramos el algoritmo para hallar matching. Al finalizar habrá filas sin matcher (las de \textit{s}).
			
			Sean:
			\begin{itemize}
				\item 
			\end{itemize}
	
	\section{Teorema del matrimonio}
	
	
	\section{Si G es bipartito $\Rightarrow \chi '(G) = \Delta $}

	
	\section{Teorema cota de Hamming}
	
	
	\section{Sea H una matriz de chequeo de un código C, pruebe que:}
	
		\subsection{$\delta (C) =$ mínimo número de columnas linealmente dependientes de H}
		
		\subsection{Si H no tiene la columna cero ni columnas respetidas $\Rightarrow$ C corrige al menos un error}


	\section{Sea C un código cíclico de dimensión \textit{k} y longitud \textit{n} y sea $g(x)$ su polinomio generador, probar que:}
	
		\subsection{C está formado por los múltiplos de $g(x)$ de grado menor a \textit{n}}
		
		\subsection{El grado de $g(x)$ es $n-k$}
		
		\subsection{$g(x)$ divide a $1+x^{n}$}
		
		

\chapter{Parte C}

	\section{4-COLOR $\leq_{\textit{p}}$ SAT}
	
	\section{3-SAT es NP-Completo}
	
	\section{3-COLOR es NP-Completo}
	
	
\begin{thebibliography}{X}
\bibitem{Dan} \textsc{Curto Agustín },
<<Matemática Discreta II, apuntes de clase>>,
\textit{FaMAF, UNC}.
\bibitem{Baz} \textsc{Maximiliano Illbele},
<<Resumen de Discreta II, 16 de agosto de 2012>>,
\textit{FaMAF, UNC}.
\end{thebibliography}

\end{document}
